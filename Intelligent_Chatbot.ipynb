{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikeshchaudhari/Chatbot/blob/main/Intelligent_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a0m_FSWC8Tc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c14WgWDtqZqM",
        "outputId": "e31ea752-df0b-4deb-b4c5-e31fcf037273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intelligent Chatbot\n",
            ">> User: hii\n",
            ">> BERT ChatBot: Our return policy allows you to return products within 30 days of purchase for a full refund, provided they are in their original condition and packaging. Please refer to our Returns page for detailed instructions.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv('Ecommerce_FAQs.csv')\n",
        "\n",
        "# Check and rename columns to 'question' and 'response' if needed\n",
        "if 'prompt' in df.columns and 'response' in df.columns:\n",
        "    df.rename(columns={'prompt': 'question'}, inplace=True)\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class BERTChatBot:\n",
        "    def __init__(self, data):\n",
        "        # Initialize with the dataset (questions and responses)\n",
        "        if 'question' not in data.columns or 'response' not in data.columns:\n",
        "            raise KeyError(\"CSV file must contain 'question' and 'response' columns\")\n",
        "\n",
        "        # Store the questions and responses as a dictionary\n",
        "        self.responses = {row['question']: row['response'] for _, row in data.iterrows()}\n",
        "        self.chat_history = []\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        \"\"\"Encode the input text using BERT tokenizer and model.\"\"\"\n",
        "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "\n",
        "    def get_best_response(self, user_input):\n",
        "        \"\"\"Find the most similar response from predefined responses using cosine similarity.\"\"\"\n",
        "        user_input_embedding = self.encode_text(user_input).unsqueeze(0)\n",
        "\n",
        "        best_score = -1\n",
        "        best_response = None\n",
        "        for question, reply in self.responses.items():\n",
        "            response_embedding = self.encode_text(question).unsqueeze(0)\n",
        "            similarity = cosine_similarity(user_input_embedding.numpy(), response_embedding.numpy())\n",
        "            if similarity > best_score:\n",
        "                best_score = similarity\n",
        "                best_response = reply\n",
        "        return best_response\n",
        "\n",
        "    def chat(self):\n",
        "        \"\"\"Run the chat interface.\"\"\"\n",
        "        print(\"Intelligent Chatbot\")\n",
        "        while True:\n",
        "            user_input = input(\">> User: \")\n",
        "            if user_input.lower() in ['bye', 'quit', 'exit']:\n",
        "                print(\"BERT ChatBot: Goodbye!\")\n",
        "                break\n",
        "            response = self.get_best_response(user_input)\n",
        "            print(f\">> BERT ChatBot: {response}\")\n",
        "\n",
        "# Start the chatbot with dataset loaded from CSV\n",
        "chatbot = BERTChatBot(df)\n",
        "chatbot.chat()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMew3hNOvqnY67uqQmdbCxo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}